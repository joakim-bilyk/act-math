# Stochastic Processes in Life Insurance Mathematics

Below is given the abbreviations used when referencing to books:

  - **Lund**: *Stochastic Processes in Life Insurance*: The Dynamic Approach by Jesper Lund Pedersen (2022)\cite{lund2022}

## Lebesgue-Stieltjes calculus

In context of life insurance, this chapter presents general mathematical definitions and results to describe (formalise) payment streams as well as valuation of payment streams. This chapter form the foundation for the next chapters. The definitions and results from measure and integration theory are outlined, where some are extensions of what is covered in a first course on the subject.

### CADLAG functions

Functions (sample paths) often considered in stochastic process theory are functions where discontinuities are jumps.

<blockquote class = "def">
**Definition 1.1. (Lund)** _A right-continuous $\mathbb R$-valued function $x(t)$ with finite left-limits defined on $[0,\infty)$ is called CADLAG\index{CADLAG} if_

  i) $x(t)=x(t+)=\lim_{t\searrow s}x(s)$ _(right-continuous),_
  ii) $x(t-)=\lim_{t\nearrow s}x(s)$ _exists for all $t$._
  
_A left-continuous function on $(0,\infty)$ with right-limits on $[0, \infty)$ is called CAGLAD\index{CAGLAD}._

</blockquote>

The jump function of a CADLAG function $x(t)$ is defined by

$$
\Delta x(t)=x(t)-x(t-).
$$

for $t>0$ and is the size of the jump at point $t$. Thus a CADLAG function can only have jump discontinuities and the jump discontinuities is at most countable as stated in the next proposition.

<blockquote class = "prop">

**Proposition 1.2. (Lund)** _A CADLAG function $x : [0, \infty) \to \mathbb R$ has at most countable many discontinuity points, that is, the set of jump times $D_x = \{t > 0 : \Delta x(t)\ne 0\}$ is at most countable._

</blockquote>

Some basic properties of CADLAG functions are summarised in the next result.

<blockquote class = "prop">

**Proposition 1.3. (Lund)** _Let $x$ and $x_i$ for $i=1,...,N$ be CADLAG functions and $\alpha_i$ be constants then_

  i) $\sum_{i=1}^N \alpha_ix_i(t)$ _is CADLAG,_
  ii) $x$ _is a Borel function,_
  iii) $x$ _is continuous in $t$ if and only if $\Delta x(t)=0$,_
  iv) _Uniform limit of a sequence of CADLAG functions on bounded intervals is itself CADLAG and_
  v) $x$ _can be approximated by a sequence of piecewise constant functions._

</blockquote>

### Functions of finite variation

The mathematical concept to the notion of payment streams is variation. Moreover, variation is the foundation of integration theory. Variation measures the total up-and-down movement of a function, that is, the total vertical distance traveled by the function. Thus, a function of finite variation is a function that wiggles finitely. Variation is also applied in theory of stochastic processes, stochastic control theory, and other subjects.

<blockquote class = "def">
**Definition 2.2. (Lund) (Variation)**\index{Variation} _The variation of the function $x : [0, \infty) \to\mathbb R$ on the interval $[0, t]$ is defined by_

$$
V^x(t)=\sup\sum_{i=1}^n\vert x(t_i)-x(t_{i-1})\vert
$$

_and the positive and negative variation of the function $x$ is given by, respectively_

$$
V^x_+(t)=\sup\sum_{i=1}^n\big( x(t_i)-x(t_{i-1})\big)^+\quad \text{and}\quad V^x_-(t)=\sup\sum_{i=1}^n\big( x(t_i)-x(t_{i-1})\big)^-.
$$

_where the supremums are over all finite partitions $0 = t_0<t_1<\cdots<t_{n-1}<t_n=t$ of $[0,t]$. The function x is of finite variation if $V^x(t)<\infty$ for all $t\ge 0$_

</blockquote>

<blockquote class = "prop">

**Proposition 2.3. (Lund)** _Let $x$ and $x_i$ for $i=1,...,n$ be functions and $\alpha_i$ be constants then_

  i) _$V^x(t)$, $V^x_+(t)$ and $V^x_-(t)$ are increasing functions._
  ii) _If $x$ is increasing or decreasing then it is of finite variation._
  iii) _If $x_1,...,x_n$ are of finite variation then $\sum_{i=1}^n\alpha_ix_i(t)$ is of finite variation._

</blockquote>

<blockquote class = "lem">

**Lemma 2.5. (Lund) (Jordan decomposition)**\index{Jordan decomposition} _Let $x$ be af function of finite variation. Then_

$$
x(t)=x(0)+V_+^x(t)-V_-^x(t)\quad\text{and}\quad V^x(t)=V_+^x(t)+V_-^x(t).
$$

</blockquote>

<blockquote class = "thm">

**Theorem 2.6. (Lund) (Jordan decomposition)** _A function $x$ is of finite variation if and only if $x$ is the difference of two increasing functions $a_+$ and $a_-$. In that case, we have_

$$
V_{\pm}^x(t)-V_{\pm}^x(s)\le V_{\pm}^{a_+-a_-}(t)-V_{\pm}^{a_+-a_-}(s).
$$

</blockquote>

<blockquote class = "prop">

**Proposition 2.7. (Lund)** _Let $x$ be a function of finite variation. Then the left-limit $x(t-)$ for $t>0$ and right-limit $x(t+)$ exist and $x$ has at most countable many discontinuity points. Moreover, the jumps of the variation function coincide with the absolute value of the corresponding points._

</blockquote>

#### FV-functions

Right-continuous finite variation functions are an important class of func- tions for measure theory as well for sample paths of stochastic processes.

<blockquote class = "def">

**Definition 2.8. (Lund) (FV-functions)**\index{FV-functions} _A function $x : [0,\infty) \to \mathbb R$ is an FV-function if _$x(t)$ is of finite variation and is CADLAG._

</blockquote>

<blockquote class = "prop">

**Proposition 2.9. (Lund)** _Let $x$ and $x_i$ for $i=1,...,n$ be FV-functions and $\alpha_i$ be constants then_

  i) _$V^x$ and $V_\pm^x$ are increasing CADLAG functions._
  ii) _$\sum_{i=1}^n \alpha_ix_i(t)$ is a FV-function._

</blockquote>

<blockquote class = "thm">

**Theorem 2.10. (Lund) (Jordan decomposition)** _An FV-function $x$ may be decomposed into_

$$
x(t)=x(0)+x^d(t)+x^c(t)
$$

_where $x^d$ is a piece-wise constant jump function and $x^c$ is a continuous function FV-function._

</blockquote>

Obviously we can simply find a solution with

$$
x^d(t)=\sum_{0\le s\le t}\Delta x(s)\quad \text{and}\quad x^c(t)=x(t)-x(0)-x^d(t).
$$

<blockquote class = "prop">

**Proposition 2.12. (Lund) (Lebesgue decomposition of function of finite variation)**\index{Lebesgue decomposition} _An FV-function $x$ can be written as_

$$
x(t)=x(0)+x^d(t)+x^{ac}(t)+x^{sc}(t),
$$

_where $x^d$ is a pure jump function (piece-wise constant function), $x^{ac}$ is an absolutely continuous function and $x^{sc}$ is a singular continuous FV-function._

</blockquote>

We recall that an absolutely continuous function $x$ is a function on the form

$$
x(t)=\int_0^t\lambda(s)\ ds,
$$

for some continuous function $\lambda$.

### Lebesgue-Stieltjes integration

Lebesgue-Stieltjes integrals are at the core of this section. The starting point is to define integrals with respect to increasing functions using general theory of measures and integrations. Then using Jordan decomposition to deal with the case of integration with respect to functions of finite variation.

<blockquote class = "def">

**Definition 3.1. (Lund) (Lebesgue-Stieltjes measure)**\index{Lebesgue-Stieltjes measure} _A measure $\mu$ on $((0,\infty),\mathcal B(0,\infty))$ is a Lebesgue-Stieltjes measure if $\mu(A)<\infty$ for every bounded interval $A\subseteq (0,\infty)$._

</blockquote>

<blockquote class = "prop">

**Proposition 3.2. (Lund) (Lebesgue-Stieltjes decomposition)** _There is a one-to-one correspondence between CADLAG increasing functions (up to addition of a constant) and Lebesgue-Stieltjes measures, given by $\mu((s,t])=a(t)-a(t)$ for all $0\le s< t$._

</blockquote>

For Lebesgue-Stieltjes measures, we can introduce integrals with respect to increasing functions.

<blockquote class = "def">

**Definition 3.4. (Lund) (Lebesgue-Stieltjes integral)**\index{Lebesgue-Stieltjes integral} _Let $a : [0,\infty) \to \mathbb R$ be an increasing CADLAG function. A Borel function $f:(0,\infty)\to\mathbb R$ is $a$-integrable if_

$$
\int_{(0,\infty)}\vert f(t)\vert\ d\lambda ^a(t):=\int_{(0,\infty)}\vert f(t)\vert\ da(t)<\infty
$$

_and we define the Lebesque-Stieljes integral as_

$$
\int_s^tf(u)\ da(u)=\int_s^t f(u)\lambda^a(u)
$$

_where_

$$
\lambda^a(t)=\lambda(\{x : g(x)\in (s,t]\})=a(t)-a(s),\quad g(x)=\inf\{t>0 : a(t)\ge x\}.
$$

_and $\lambda$ denotes the Lebesgue-measure on $((0,\infty),\mathcal B(0,\infty))$._

</blockquote>

We will for ease of calculation use that for an integrator function $B$ we may decompose the measure in terms of the discrete function and the continuous functions obtaining:

$$
\int f(u)\ dB(u)=\int f(u)\ dB^d(u)+\int f(u)\ dB^{ac}(u)+\int f(u)\ dB^{sc}(u).
$$

If furthermore $B$ is the sum of FV functions we can accordingly integrate over all functions in the sum that makes up $B$. We have the following results regarding some elementary integrals.

<blockquote class = "prop">

**Proposition 3.11. (Lund)** _Let $x$ be an FV-function then (assuming integrability) the following holds._
\begin{align*}
\text{(i):}&\quad\int_s^t\ dx(u)=\lambda^x((s,t])=x(t)-x(s),\\
\text{(ii):}&\quad \int_{\{t\}}f(u)\ dx(u)=f(t)\Delta x(t),\\
\text{(iii):}&\quad x(t)=c\Longrightarrow \int_s^t f(u)\ dx(u)=0,\\
\text{(iv):}&\quad \int_s^t f(u)\ dx^d(u)=\sum_{s< u\le t} f(u)\Delta x(u),\\
\text{(v):}&\quad \int_s^t f(u)\ dx^{ac}(u)=\int_s^t f(u)\varphi(u)\ du,\\
\text{(vi):}&\quad \int_s^t \Delta f(u)\ dx(u)=\sum_{s< u\le t} \Delta f(u)\Delta x(u).
\end{align*}
</blockquote>
If we can write a function $f$ as

$$
f(t)=f_0+\int_0^t\varphi(u)\ dx(u)
$$

then we can write this on **differential form**\index{differential form}

$$
df(t)=\varphi(u)\ dx(u),\qquad f(0)=f_0.
$$

This notation is equivalent with the integral above but is often easier to write down. We also say the $f$ has *dynamics*\index{dynamics} $\varphi(u)\ dx(u)$.

### Change of variables formula (Ito formula for FV-functions)

In practice the definition of a Lebesgue-Stieltjes integral is not applied for a calculation of an integral. The Lebesgue-Stieltjes integral is useful by reason of its properties and rules which it can be manipulated. The previous section explores some of the properties of the Lebesgue-Stieltjes integral and this section explores the rules which integrals can be manipulated.

The next result is a cornerstone for FV-functions.

<blockquote class = "thm">

**Theorem 4.1. (Lund) (Integration by parts formula)**\index{Integration by parts formula} _If $x$ and $y$ are two FV-functions then the function $z(t)=x(t)y(t)$ is given by_

$$
z(t)=z(0)+\int_0^t y(s-)\ dx(s)+\int_0^t x(s-)\ dy(s)+\sum_{0<s\le t}\Delta x(s)\Delta y(s)
$$

_or on differential form_

$$
dz(t)=y(s-)\ dx(s)+ x(s-)\ dy(s)+\Delta x(s)\Delta y(s).
$$

</blockquote>

<blockquote class = "thm">

**Theorem 4.2. (Lund) (Change of variable formula — Ito formula for FV-functions)**\index{Ito formula}\index{Change of variable formula} _Let $f$ be a $C^1$-function and let $x(t)$ be a FV-function. Then $z(t)=f(x(t))$ is an FV-function and_

$$
z(t)=z(0)+\int_0^tf'(x(s))\ dx^c(s)+\sum_{0<s\le t}\Big(f(x(s))-f(x(s-))\Big)
$$

_or on differential form_

$$
dz(t)=f'(x(t))\ dx^c(t)+\Big(f(x(t))-f(x(t-))\Big)\ dN^x(t)
$$

_where $N^x(t)=\#\{0<s\le t: x(s)\ne x(s-)\}$._

</blockquote>

Below is the $n$-dimensional version of Change of variable formula. The proof is based on the same method to prove the one-dimensional version (Theorem 4.2).

<blockquote class = "thm">

**Theorem 4.3. (Lund) (Change of variable formula — Ito formula for FV-functions)** _Let $f : \mathbb R^n\to\mathbb R$ be a $C^1$-function and let $x(t)=\big(x_1(t),...,x_n(t)\big)$ be an $n$-dimensional function of FV-functions. Then $z(t)=f(x(t))$ is an FV-function and_

$$
z(t)=z(0)+\sum_{i=1}^n\int_0^t\frac{\partial}{\partial x_i}f(x(s))\ dx_i^c(s)+\sum_{0<s\le t}\Big(f(x(s))-f(x(s-))\Big)
$$

_or on differential form_

$$
dz(t)=\sum_{i=1}^n\frac{\partial}{\partial x_i}f(x(s))\ dx_i^c(s)+\Big(f(x(t))-f(x(t-))\Big)\ dN^x(t).
$$

</blockquote>

For the applications in the next sections we use the following speciale version of Change of variable formula.

<blockquote class = "prop">

**Corollary 4.4. (Lund)** _Let $f^j : \mathbb R^n\to\mathbb R$ be a $C^1$-functions for $j=1,...,m$ and let $z : [0,\infty) \to \{1,..,m\}$ be a pure jump function. Let furthermore $x(t)=\big(x_1(t),...,x_n(t)\big)$ be an $n$-dimensional function of FV-functions. Assume that $x$ has jumps on a subset of the jump times of $z$. Then $g(t)=f^{z(t)}(x(t))$ is an FV-function and_

$$
g(t)=g(0)+\sum_{i=1}^n\int_0^t\frac{\partial}{\partial x_i}f^{z(s)}(x(s))\ dx_i^c(s)+\int_0^t\left(f^{z(s)}(x(s))-f^{z(s-)}(x(s-))\right)\ dn(s)
$$

_where $n(t)=\#\{0<s\le t: z(s)\ne z(s-)\}$. This is equivalent to the differential form_

$$
dg(t)=\sum_{i=1}^n\frac{\partial}{\partial x_i}f^{z(s)}(x(s))\ dx_i^c(s)+\left(f^{z(s)}(x(s))-f^{z(s-)}(x(s-))\right)\ dn(s).
$$

</blockquote>

Hence $g$ evolves according to the selected function $f^j$ given by the state of $z$ and jumps to another function $f^k$ on $z(t)=k$ and $z(t-)=j$. This intuitive insight is a very important result when we later will be writing down the dynamics of the reserve.

As an application of the change of variables formula is Exponential formulas, also called the Dol ́eans exponential. These solutions have many applications.

<blockquote class = "thm">

**Theorem 4.6. (Lund) (Doleans exponential formula for FV-functions)** _Let $x$ be an FV-function. The unique solution of_

$$
dy(t)=y(t-)\ dx(t),\qquad y(0)=y_0,
$$

_is given by_

$$
y(t)=y_0\exp(x^c(t))\prod_{0<s\le t}\big(1+\Delta x(s)\big).
$$

</blockquote>

## Stochastic processes

In this chapter we will study the stochastic processes used for modelling in the insurance and statistical part of the note. All the life insurance and statistical models in this note are in continuous time. In what follows $(\Omega,\mathcal F,\mathbb P)$ denotes a given probability space.

### General theory of stochastic processes

#### Stochastic processes

This is a short introduction to a few concepts and terminology concerning the general theory of stochastic processes. Moreover basic notations are introduced which are used in the sequel.

A stochastic process is a mathematical model for the occurrence, at each moment after the initial time, of a random phenomenon. Thus, a stochastic process is a family of stochastic variables indexed by time. In this note the state space $\mathcal X$ is $\mathbb R$, $\mathbb Z$, $\mathbb R^d$, or a subset of those.

<blockquote class = "def">

**Definition 6.1. (Lund) (Continuous-time stochastic process)**\index{Continuous-time stochastic process} _A continuous-time stochastic process with state space $\mathcal X$ is a family of stochastic variables $(X(t),t \ge 0)$ where $X(t)$ takes values in $\mathcal X$ for all $t \ge 0$._

</blockquote>

A stochastic process $X(t)$ is called

  * Continuous if $X(t;\omega)$ is continuous almost surely,
  * CADLAG if $X(t;\omega)$ is CADLAG almost surely,
  * Of finite variation if $X(t;\omega)$ is of finite variation almost surely,

If the process $X(t)$ is CADLAG, we can define two other processes by

  * $X(t-)=\lim_{h\to 0}X(t-h)$ for $t>0$ and we set $X(0-)=X(0)$.
  * $\Delta X(t)=X(t)-X(t-)$ for $t>0$ and we set $\Delta X(0)=0$.

We also have that $X(t-)$ is CAGLAD (left continuous with right limits).

#### Filtrations and stopping times

The definition of a stochastic process has the feature of a flow of time, in which, at any time $t \ge 0$, we can talk about a past, present, and future. Filtrations are heuristically the collection of events which may occur before or at time $t$.

<blockquote class = "def">

**Definition 6.2. (Lund) (Filtration)**\index{Filtration} _A filtration $\mathcal F(t)$ is an increasing family of sub-$\sigma$-algebras of $\mathcal F$. That is, for each $t$ there is a $\sigma$-algebra $\mathcal F(t)$ and $\mathcal F(s)\subseteq \mathcal F(t)$ for $0\le s<t<\infty$. Moreover_

  * _$\mathcal F(t-)=\sigma(\cup_{s<t} \mathcal F(s))$ is the information strictly prior to $t$,_
  * _$\mathcal F(t+)=\cap_{\varepsilon >0}\mathcal F(t+\varepsilon)$ is the information immidieately after $t$._

</blockquote>

The natural filtration of a stochastic process $X(t)$ is the simplest choice of a filtration that is generated by the process itself and is denoted by

$$
\mathcal F^X(t) = \sigma (X(s) : 0 \le  s \le t).
$$

A filtration $\mathcal F(t)$ satisfies the *usual conditions* (les conditions habituelles) if it is right-continuous and $\mathcal F(0)$ contains all $\mathbb P$-negligible events in $\mathcal F$, that is, if $A \subseteq  B \in \mathcal F$ such that $P(B) = 0$ then $A \in\mathcal F(0)$.

<blockquote class = "def">

**Definition 6.4. (Lund) (Adapted process)**\index{Adapted process} _A stochastic process $X(t)$ is adapted to the filtration $\mathcal F(t)$ if, $X(t)$ is an $\mathcal F(t)$-measurable stochastic variable for each $t$._

</blockquote>

Note that any process $X(t)$ is adapted to its natural filtration $\mathcal F^X(t)$. In fact, $\mathcal F^X(t)$ is the smallest filtration to which $X(t)$ is adapted.

<blockquote class = "def">

**Definition 6.5. (Lund) (Stopping time)**\index{Stopping time} _A $[0,\infty]$-valued random variable $\tau$ is a stopping time with respect to the filtration $\mathcal F(t)$ if_

$$
\{\tau\le t\}\in \mathcal F(t)
$$

_for all $t\ge 0$. Moreover_

$$
\mathcal F(\tau)=\{A\in\mathcal F\ \vert\ A\cap \{\tau\le t\}\in\mathcal F(t),\ \text{for all}\ t\ge 0\}
$$

_is a $\sigma$-algebra containing all information at the stopping time $\tau$._

</blockquote>

<blockquote class = "lem">

**Lemma 6.6. (Lund)** _Let $\tau$ be a $[0,\infty]$-valued random variable and let $Z$ be a random variable. Then_

  (i) _$\tau$ is a stopping time with respect to a filtration $\mathcal F(t)$ if an only if the process $t\mapsto \tau 1_{[\tau,\infty)}(t)$ is adapted to $\mathcal F(t)$ and $\{\tau = 0\}\in\mathcal F(0)$.,_
  (ii) _If $\tau$ is a stopping time with respect to a filtration $\mathcal F(t)$. Then $Z$ is measurable with respect to $\mathcal F(t)$ if and only if the process $t\mapsto Z1_{[\tau,\infty)}(t)$ is adapted to $\mathcal F(t)$._
  (iii) _$\mathcal F(t)=\sigma(1_{\{\tau = 0\}},\tau 1_{[\tau,\infty)}(t),Z1_{[\tau,\infty)}(t))$ is the smallest filtration such that $\tau$ is a stopping time and $Z$ is measurable with respect to $\mathcal F(t)$_

</blockquote>

#### Progressive and predictable measurability

Implicit in the definition of a stochastic process is the assumption that each $X(t)$ is measurable. But a stochastic process is really a function of the pair of variables $(t, \omega)$ and it is convenient to have some measurability properties.

<blockquote class = "def">

**Definition 6.7. (Lund)** _The stochastic process $X(t)$ is measurable if $(t,\omega) \mapsto X(t,\omega)$ is measurable with respect to $\mathcal B([0, \infty)) \otimes \mathcal F$._

</blockquote>

All the sample paths of a measurable process are Borel functions. But the process does not need to be adapted. The following definition relates measurability in $t$ and $\omega$ with the filtration.

<blockquote class = "def">

**Definition 6.8. (Lund)** _Let $\mathcal F(t)$ be a filtration and define the progressive $\sigma$-algebra by_

$$
Pr(\mathcal F)=\Big\{A\in \mathcal B([0,\infty)) \otimes \mathcal F\ \vert\ A \cap ([0,s] \times \Omega)\in \mathcal B([0,s])\otimes \mathcal F(s)\ \text{for all}\ s\ge 0\Big\}.
$$

_A stochastic process $X(t)$ is progressive if the mapping $(t,\omega) \mapsto X(t,\omega)$ is measurable with respect to $Pr(\mathcal F)$._

</blockquote>

<blockquote class = "lem">

**Lemma 6.9. (Lund)** _A stochastic process $X(t)$ is progressive if and only if the map $(t,\omega) \mapsto X(t,\omega)$ restricted to $[0, s] \times\Omega$ is measurable with respect to $\mathcal B([0, s]) \otimes\mathcal F (s)$ for every $s \ge 0$._

</blockquote>

An important example of a progressive process is provided by the following lemma.

<blockquote class = "lem">

**Lemma 6.10. (Lund)** _If an adapted process $X(t)$ is CADLAG or CAGLAD then the process $X(t)$ is progressive._

</blockquote>

<blockquote class = "lem">

**Lemma 6.11. (Lund)** _Let $(X (t), t \ge 0)$ be a progressive process. If $\tau$ is a stopping time then the stopped process $(X(\min\{\tau,t\}),t \ge 0)$ is progressive and the random variable $X(\tau)1[0,∞)(\tau)$ is measurable with respect to $\mathcal F(\tau)$._

</blockquote>

<blockquote class = "def">

**Definition 6.12. (Lund) (Elementary predictable sets)**\index{Elementary predictable sets} _Let $\mathcal F(t)$ be a filtration and let the elementary predictable sets be_

$$
\mathcal E=\Big\{\{0\}\times F\ \vert\ F\in\mathcal F(0)\Big\}\cup\Big\{(s,t]\times F\ \vert\ F\in\mathcal F(s), 0\le s<t<\infty\Big\}.
$$

_The predictable $\sigma$-algebra $\mathcal P(\mathcal F)$ is the $\sigma$-algebra that is generated by the elementary predictable sets, that is,_

$$
\mathcal P(\mathcal F) = \sigma(\mathcal E).
$$

_A stochastic process $X(t)$ is predictable if the mapping $(t,\omega) \mapsto X(t,\omega)$ is measurable with respect to the predictable $\sigma$-algebra $\mathcal P(\mathcal F)$._

</blockquote>

The next proposition gives conditions for a process to be predictable.

<blockquote class = "prop">

**Proposition 6.13. (Lund)** _The process $X(t)$ is predictable if one of the following conditions is satisfied:_

  (i) _$X(t)$ is an adapted CAGLAD process._
  (ii) _$X(t)$ is a measurable (Borel) deterministic process._
  (iii) _$X(t)$ is a Borel-measurable function of a predictable process._

</blockquote>

<blockquote class = "prop">

**Corollary 6.14. (Lund)** _If $X(t)$ is an adapted CADLAG process, then $X(t)$ is a progressive process and $X(t−)$ is a predictable process. Moreover, if $X(t)$ is predictable, then $\Delta X(t)$ is predictable._

</blockquote>

<blockquote class = "prop">

**Proposition 6.15. (Lund)** _Let $\mathcal F(t)$ be a filtration._

  (i) _If $X(t)$ is a predictable process then $X(t)$ is adapted to the filtration $\mathcal F^−(t) =\mathcal F(t−)$. Particularly, $X(t)$ is adapted to the filtration $\mathcal F(t)$._
  (ii) _If $X(t)$ is a predictable process then $X(t)$ is also progressive._
  (iii) _If $X(t)$ is a progressive process then $X(t)$ is adapted to the filtration $\mathcal F(t)$._
  (iv) _If $X(t)$ is a progressive process then $X(t)$ is also measurable._

</blockquote>

### Markov processes

For modeling, Markov processes are mathematical tractable and allows for computations of for example reserves in the multi-state contract.

<blockquote class = "def">

**Definition 7.1. (Lund)** _An adapted stochastic process $X(t)$ is a Markov process with respect to the filtration $\mathcal F(t)$ if_

$$
\mathbb P(X(t)\in A\ \vert\ \mathcal F(s))=\mathbb P(X(t)\in A\ \vert\ X(s))\quad \text{(Markov property)}
$$

_for all $0\le s< t$ and all $A\in\mathcal B(\mathbb R)$._

</blockquote>

A process is Markov, intuitively speaking, if today to make a prediction on what is going to happen in the future, it is useless to know anything more about the whole past up to today than the present state.

In the insurance part we study present values of future payments, and therefore we need other formulations of the Markov property. Let $\mathcal F^t = \sigma(X(s)\ \vert\ s \ge t)$ be the information generated by the process in the future. The result has the interpretation that the future depends on the past only through the present.

<blockquote class = "prop">

**Proposition 7.2. (Lund)** _Let $X(t)$ be a Markov process. If $Y$ is a bounded $\mathcal F^t$ measurable random variable, then_

$$
\mathbb E[Y\ \vert\ \mathcal F(t)]=\mathbb E[Y\ \vert\ X(t)].
$$

</blockquote>

### Finite variation processes

As it is discussed in the section *"Life insurance models"* below, the sample paths of a payment process (or function) is of finite variation. Thus processes of finite variation (FV-process), that is, the sample paths are of finite variation are building blocks for the theory of payment streams for an insurance policy. Below is the formal definition.

<blockquote class = "def">

**Definition 8.1. (Lund)** _A process $X(t)$ is called an FV-process if_

  (i) _$X(t)$ is adapted to a given filtration._
  (ii) _The sample paths $t \mapsto X(t)$ are almost surely FV-functions._

</blockquote>

By Proposition 2.3, if $X(t)$ and $Y (t)$ are FV-processes then $\alpha X(t) + \beta Y (t)$ is an FV-process, where $\alpha$ and $\beta$ are two constants.

<blockquote class = "def">

**Definition 8.2. (Lund)** _An $n$-dimensional process $(X(t), t \ge 0) = ((X^1(t),..., X^n(t)), t \ge 0)$ is called a $n$-dimensional FV-process if the component process $(X^i(t),t \ge 0)$ is an FV-process for $i = 1,...,n$._

</blockquote>

### Finite variation martingales

The basic approach employed in the insurance part and in the statistical part is martingale methods. Let $\mathcal F(t)$ be a given filtration.

#### Basic martingale theory

<blockquote class = "def">

**Definition 9.1. (Lund)** _A process $M(t)$ is an $\mathcal F(t)$-martingale if_

  (i) _$M(t)$ is adapted to the filtration._
  (ii) _$M(t)$ is integrable, that is, $\mathbb E\vert M(t)\vert<\infty$ for all $t$._
  (iii) _$\mathbb E[M(t)\ \vert\ \mathcal F(s)]=M(s)$ for all $0\le s\le t$ (martingale property)._

</blockquote>

The process $M(t)$ is a submartingale if the latter condition is replaced by the inequality $\mathbb E[M (t)\ \vert\ \mathcal F (s)] \ge M (s)$ for all $0 \le  s \le t$. With the inequality reversed, $M (t)$ is a martingale.

Taking expectation of the martingale property gives that

$$
\mathbb E[M(t)]=\mathbb E[M(s)]=\mathbb E[M(0)].
$$

The next proposition gives a construction of martingales.

<blockquote class = "prop">

**Proposition 9.3. (Lund)** _Let $Y$ be an integrable random variable. Then $M(t)=\mathbb E[Y\ \vert\ \mathcal F(t)]$ is a martingale._

</blockquote>

#### FV-martingales

Martingales of finite variation are of partially interest in this note. For short notation we denote a martingale with finite variation as an FV-martingale and the formal definition is given below.

<blockquote class = "def">

**Definition 9.4. (Lund)** _A process $M(t)$ is an FV-martingale if_

  (i) _$M(t)$ is an integrable FV-process._
  (ii) _$\mathbb E[M(t)\ \vert\ \mathcal F(s)]=M(s)$ for all $0\le s\le t$ (martingale property)._

</blockquote>

We have the following informal criterion: $M(t)$ is an FV-martingale if and only if $\mathbb E[dM(t)\ \vert\ \mathcal F(t−)] = 0$ for all $t$. Indeed, by adding up increments of $M (t)$ over small subintervals $[u, u + du)$ partitioning $[s + ds, t + dt) = (s, t]$ for $s < t$, we have informally that
\begin{align*}
\mathbb E[M(t)\ \vert\ \mathbb F(s)]-M(s)&=\mathbb E[M(t)-M(s)\ \vert\ \mathbb F(s)]\\
&=\mathbb E\left[\left.\int_s^t dM(u)\ \right\vert\ \mathbb F(s)\right]\\
&=\int_s^t\mathbb E\left[\left. dM(u)\ \right\vert\ \mathbb F(s)\right]\\
&=\int_s^t\mathbb E\left[\left.E\left[\left. dM(u)\ \right\vert\ \mathbb F(u-)\right]\ \right\vert\ \mathbb F(s)\right]\\
&=0.
\end{align*}
<blockquote class = "prop">
**Proposition 9.5. (Lund)** _If $X(t)$ is a continuous FV-martingale, then $X(t)$ is a constant process, that is, $X(t) = X(0)$._

</blockquote>

<blockquote class = "prop">

**Proposition 9.6. (Lund)** _Let $X(t)$ be an FV-process. If $X(t)$ is predictable martingale then $X(t)$ is a constant process, that is, $X(t) = X(0)$._

</blockquote>

The two propositions will be applied in the insurance part with following formulation.

<blockquote class = "prop">

**Corollary 9.7. (Lund)** _If $X(t)$ is a martingale with representation_

$$
X(t)=X(0)+M(t)+B(t)
$$

_where $M(t)$ is an FV-martingale and $B(t)$ is a predictable FV-process, then $B(t)$ is a constant process. In the special case that $B(t) = \int_0^tH(s) ds$ where $H(t)$ is a progressive process. Then $H(t)$ is equal to zero._

</blockquote>

#### Doob-Meyer decomposition: Predictable compensators

An FV-process can be decomposed into a martingale part and a predictable part. The decomposition is called the Doob-Meyer decomposition and is a deep result in martingale theory. The Doob-Meyer decom- position is in general formulated for submartingales (or the difference of two submartingales). Since an integrable increasing process is a submartingale and an integrable FV-process is the difference of two submartingales, the Doob-Meyer decomposition below is first formulated for increasing processes and then for FV-processes.

<blockquote class = "thm">

**Theorem 9.8. (Lund) (Doob-Meyer decomposition for increasing processes)** _Assume that the filtration $\mathcal F(t)$ satisfies the usual conditions. Suppose $X(t)$ is an adapted increasing CADLAG process that is locally integrable (there is a sequence of stopping times $(\tau_n, n = 1, 2, . . .)$, increasing to $\infty$, such that $E[X (\tau_n ) − X (0)] < \infty$ for every $n$)._

_Then there is a unique predictable CADLAG increasing process $\Lambda^X(t)$ with $\Lambda^X(0) = 0$ such that $X(t) − \Lambda^X(t)$ is a local FV-martingale. Moreover, if $E[X(t) − X(0)] < \infty$ or $E[\Lambda^X(t)] < \infty$ then $X(t) − \Lambda^X(t)$ is a martingale._

</blockquote>

In other words, there exists a predictable CADLAG increasing process $\Lambda^X(t)$ with $\Lambda^X(0) = 0$ and a (local) FV-martingale $M(t)$ with $M(0) = 0$ such that increasing process $X(t)$ has the decomposition

$$
X(t)=X(0)+M(t)+\Lambda^X(t).
$$

In this note we avoid local martingales and we will always assume in what follows that we have enough integrability, $E[X(t)−X(0)] < \infty$ for all $t$, such that the process $M(t)$ is a martingale. In this case note that Proposition 9.6 gives the uniqueness of the predictable compensator $\Lambda^X(t)$. Recall that an FV-process $X(t)$ of integrable variation ($E[V^X(t)] < \infty$ for all $t$) can be decomposed into the difference of two (adapted CADLAG) integrable increasing processes. Then we can apply the Doob-Meyer decomposition for increasing processes on both increasing processes and get the following version of Doob-Meyer decomposition.

<blockquote class = "thm">

**Theorem 9.9. (Lund) (Doob-Meyer decomposition for FV-processes)** _Assume that the filtration $\mathcal F(t)$ satisfies the usual conditions. Suppose $X(t)$ is an integrable FV-process ($E[V^X(t)] < \infty$ for all $t$). Then there is a unique integrable predictable FV-process $\Lambda^X (t)$ with $\Lambda^X (0) = 0$ such that_

$$
X(t)-\Lambda^X(t)
$$

_is an FV-martingale._

</blockquote>

Again, $X(t)$ has the decomposition

$$
X(t)=X(0)+M(t)+\Lambda^X(t).
$$

where $M(t)$ is an FV-martingale with $M(0) = 0$.

<blockquote class = "def">

**Definition 9.10. (Lund)** _The predictable FV-process $\Lambda^X (t)$ from Doob-Meyer decomposition is called the predictable compensator of $X(t)$._

</blockquote>

As already used in the argument for extending Theorem 9.8 to Theorem 9.9, the predictable compensator is linear in the following sense.

<blockquote class = "lem">

**Lemma 9.11. (Lund)** _Let $X_1(t)$ and $X_2(t)$ be two FV-processes of integrable variation and let $\Lambda_1(t)$ and $\Lambda_2(t)$ be the associated predictable compensators, respectively. Let $\alpha$ and $\beta$ be two constants. Then the FV-process $X(t) = \alpha X_1(t) + \beta X_2(t)$ has predictable compensator given by $\Lambda(t) = \alpha\Lambda_1(t) + \beta\Lambda_2(t)$._

</blockquote>

By the martingale property of $M(t) = X(t) − \Lambda^X(t)$ we get that

$$
\mathbb E[X(t)-X(s)\ \vert\ \mathcal F(s)]=\mathbb E[\Lambda^X(t)-\Lambda^X(s)\ \vert\ \mathcal F(s)]
$$

for $0\le s< t$. By setting $s=0$ and taking expectaion gives that

$$
\mathbb E[X(t)-X(0)]=\mathbb E[\Lambda^X(t)].
$$

In this note we will be interested in the case that predictable intensities exists, that is, a so- called absolutely continuous case. By the short informal notation we have that the intensity process is given by $\lambda^X(t)dt = \mathbb E[dX(t)\ \vert\ \mathcal F(t−)]$. The formal definition is the following.

<blockquote class = "def">

**Definition 9.13. (Lund)** _Let $X(t)$ be an FV-process with integrable variation. The FV-process $X(t)$ has intensity process $\lambda^X(t)$ if_

  (i) _$\lambda ^X(t)$ is a predictable process._
  (ii) _$\int_0^t\vert \lambda^X(s)\vert\ ds<\infty$ for all $t\ge 0$._
  (iii) _$\Lambda^X(t)=\int_0^t\lambda^X(s)\ ds$ for all $t\ge 0$._

</blockquote>

In the special case that $X(t)$ is an increasing process, then $\lambda^X(t) \ge 0$ is a positive process.

<blockquote class = "lem">

**Lemma 9.14. (Lund)** _Let $X_1(t)$ and $X_2(t)$ be two FV-processes with intensity processes $\lambda_1(t)$ and $\lambda_2(t)$ be the associated predictable compensators, respectively. Let $\alpha$ and $\beta$ be two constants. Then the FV-process $X(t) = \alpha X_1(t) + \beta X_2(t)$ has intensity process given by $\lambda(t) = \alpha\lambda_1(t) + \beta\lambda_2(t)$._

</blockquote>

#### Predictable variation and covariation processes

To be able to formulate the martingale central limit theorem for counting processes - which we will use in the statistical part — we need the concept of variation processes, which results from the Doob-Meyer decomposition.

Consider a square integrable FV-martingale $M(t)$. Then we know that $M^2(t)$ is also an integrable FV-process. By the Doob-Meyer decomposition theorem $M^2$ has a unique predictiable FV-process $\langle M\rangle (t)$ which is the predictable compensator of $M^2(t)$. One can show that

$$
d\left(M^2(t)\right)=2M(t-)dM(t)+\left(dM(t)\right)^2.
$$

and so the process $\langle M\rangle$ has dynamics
\begin{align*}
d\langle M\rangle (t)&=\mathbb E\left[\left.d\left(M^2(t)\right)\ \right\vert\ \mathcal F(t-)\right]\\
&=\mathbb E\left[\left.\left(dM(t)\right)^2\ \right\vert\ \mathcal F(t-)\right]\\
&=\text{Var}(dM(t)\ \vert\ \mathcal F(t-)).
\end{align*}
Furthermore, if we have two integrable FV-martingales $M_1(t)$ and $M_2(t)$ with $\mathbb E[M_1(t)M_2(t)]<\infty$ for all $t$, then we define the covariation process $\langle M_1,M_2\rangle(t)$ as the unique predictable compensator for the product process $M_1(t)M_2(t)$. Note that $\langle M,M\rangle =\langle M\rangle$. We have some properties of the covariation process:
\begin{align*}
\text{(a)}:&\qquad\langle aM_1+bM_2,M_3\rangle(t)=a\langle M_1,M_3\rangle(t)+b\langle M_2,M_3\rangle (t),\\
\text{(b)}:&\qquad\langle M_1,M_2\rangle(t)=\langle M_2,M_1\rangle(t),\\
\text{(c)}:&\qquad\langle M_1,M_2\rangle(t)=\frac{1}{4}\Big(\langle M_1+M_2\rangle(t)-\langle M_1-M_2\rangle (t)\Big),\\
\text{(d)}:&\qquad d\langle M_1,M_2\rangle(t)=\text{Cov}\Big(dM_1(t),dM_2(t)\ \vert\ \mathcal F(t-)\Big).
\end{align*}
We also have the following theorem.

<blockquote class = "thm">

**Theorem 9.15. (Lund) (Lenglart’s inequality)** _Let $M(t)$ be a square integrable FV-martingale and
$\langle M\rangle(t)$ its predictable variation process. For any $\varepsilon > 0$ and any $\delta > 0$ then_

$$
\mathbb P \left(\sup_{0\le s\le t}\vert M(s)\vert > \varepsilon\right)\le \frac{\delta}{\varepsilon^2}+\mathbb P(\langle M\rangle (t)> \delta).
$$

</blockquote>

### Integral processes

For the present value of a payment process (FV-process) it is important to form an integral of one stochastic process with respect to another. In this note, it is the Lebesgue-Stieltjes integral defined $\omega$-by-$\omega$ in the class of FV-processes. In this section, let $\mathcal F(t)$ be a given filtration.

#### Integral process and basic properties

Let $X(t)$ be an FV-process and let $H(t)$ be a progressive process. Let $\omega$ be fixed, then the sample path $t \mapsto X(t, \omega)$ is an FV-function and the sample path $t \mapsto X(t, \omega)$ is a Borel function (see Remark 6.16 ), then by Definition 3.9 we have the Lebesgue-Stieltjes integral with respect to the sample path of $H(t)$ with respect to the sample path of $X(t)$. We have then the following definition

Let $X(t)$ be an FV-process. We say that a progressive process $H(t)$ is locally $X$-integrable if

$$
\int_0^t \vert H(t,\omega)\vert dV^x(t,\omega) <\infty
$$

for all $t>0$ and all $\omega \in\Omega$. Then we define, $\omega$-by-$\omega$, the integral process of $H(t)$ with respect to $X(t)$ to be

$$
Y(t,\omega)=\int_0^tH(s,\omega)\ dX(s,\omega)
$$

the Lebesgue-Stieltjes integral.

By Proposition 3.14, the sample paths of the integral process have the following properties.

<blockquote class = "prop">

**Properties 10.1. (Lund)** _The intergral process has the following properties._

  (i) _The sample paths $t\mapsto \int_0^t H(s,\omega)\ dX(s,\omega)$ are CADLAG._
  (ii) _The sample paths $t\mapsto \int_0^t H(s,\omega)\ dX(s,\omega)$ are continuous if $t\mapsto X(t,\omega)$ is continuous._
  (iii) _The sample paths $t\mapsto \int_0^t H(s,\omega)\ dX(s,\omega)$ have finite variation._

</blockquote>

By Proposition 3.10, the calculus of the integral process is the following.

<blockquote class = "prop">

**Properties 10.2. (Lund)** _Assume that all integrals below exists and are well defined, then we have the following properties where $\alpha$ and $\beta$ are constants._

  (i) _If $H_1(t)$ and $H_2(t)$ are progressive processes and $X(t)$ is an FV-process then_
  $$\int_0^t\Big(\alpha H_1(s) + \beta H_2(s)\Big)\ dX(s)=\alpha\int_0^t H_1(s)\ dX(s)+\beta\int_0^t H_2(s)\ dX(s).$$
  (ii) _If $H(t)$ is a progressive process and $X_1(t)$ and $X_2(t)$ are two FV-processes then_
  $$\int_0^tH(s)\ d\Big(\alpha X_1(s) + \beta X_2(s)\Big)=\alpha\int_0^tH(s)\ d X_1(s)+\beta \int_0^tH(s)\ d X_2(s).$$

</blockquote>

The following proposition shows that the condition that $H(t)$ is progressive is made to insure that the integral process is adapted.

<blockquote class = "prop">

**Properties 10.3. (Lund)** _The integral process $Y(t)=\int_0^t H(s)\ dX(s)$ is adapted to the filtration $\mathcal F(t)$. Moreover, if $X(t)$ and $H(t)$ are predictable processes then the integral process $Y(t) = \int_0^t H(s)\ dX(s)$ is also predictable._

</blockquote>

Finally, let us summing up the results in this section using Proposition 10.3, Proposition 10.1, and Proposition 3.14.

<blockquote class = "prop">

**Properties 10.4. (Lund)** _Let $X(t)$ be an FV-process and let $H(t)$ be a locally $X$-integrable progressive process. Then the integral process_

$$
Y(t)=\int_0^tH(s)\ dX(s)
$$

_is an FV-process which is bilinear in $H(t)$ and $X(t)$ and has following properties._

  (i) $\Delta Y(t)=H(t)\Delta X(t)$.
  (ii) _Let $K(t)$ be a progressive process and provided that the integrals are well defined then_
  $$\int_0^t K(s)\ dY(s)=\int_0^tK(s)H(s)\ dX(s).$$
  
</blockquote>

#### FV-martingales as integrators

An important result is that the integral of a predictable process with respect to an FV-martingale is another FV-martingale. This shows how martingales, integral processes, and predictable processes are tightly linked.

<blockquote class = "prop">

**Properties 10.5. (Lund)** _Let $M(t)$ be an FV-martingale and let $H(t)$ be a predictable process satisfying_

$$
\mathbb E\left[\int_0^t\vert H(s)\vert\ dV^M(s)\right]< \infty
$$

_for every $t>0$. Then the integral process $\int_0^t H(s)\ dM(s)$ is also an FV-martingale._
  
</blockquote>

#### Predictable compensator

The predictable compensator of an integral process over a predictable process $H(t)$ with respect to $X(t)$ is given in the following proposition.

<blockquote class = "prop">

**Properties 10.6. (Lund)** _Let $X(t)$ be an FV-process of integrable variation with predictable compensator $\Lambda(t)$ and let $H(t)$ be a predictable process such that_

$$
\mathbb E\left[\int_0^t\vert H(s)\vert\ dV^X(s)\right]< \infty\ \text{or}\ \mathbb E\left[\int_0^t\vert H(s)\vert\ dV^\Lambda(s)\right]< \infty.
$$

_Then the integral process_

$$
\int_0^t H(s)\ d\Big(X(s)-\Lambda(s)\Big)=\int_0^t H(s)\ dX(s)-\int_0^t H(s)\ d\Lambda(s)
$$

_is an FV-martingale. Moreover, $\int_0^t H(s)\ d\Lambda(s)$ is the predictable compensator for the integral process $\int_0^t H(s)\ dX(s)$. In the special case that $X(t)$ has intensity process $\lambda(t)$, then_

$$
\int_0^t H(s)\ dX(s)-\int_0^t H(s)\lambda(s)\ ds
$$

_is an FV-martingale and $\int_0^t H(s)\ dX(s)$ has intensity process $H(t)\lambda (t)$._

</blockquote>

The martingale property implies that

$$
\mathbb E\left[\left.\int_s^t H(u)\ dX(u)\ \right\vert\ \mathcal F(s)\right]=\mathbb E\left[\left.\int_s^t H(u)\ d\Lambda (u)\ \right\vert\ \mathcal F(s)\right].
$$

#### Predictable variation and covariation processes

Let $M(t)$ be an FV-martingale and use the informal notation
\begin{align*}
d\left\langle \int_0^t H(s)\ dM(s)\right\rangle(t)&=\text{Var}\left(\left.d\left(\int_0^t H(s)\ dM(s)\right)\ \right\vert\ \mathcal F(t-)\right)\\
&=\text{Var}\Big(\left.H(t)\ dM(t)\ \right\vert\ \mathcal F(t-)\Big)\\
&=H^2(t)\text{Var}\Big(\left.\ dM(t)\ \right\vert\ \mathcal F(t-)\Big)\\
&=H^2(t)\ d\langle M\rangle (t).
\end{align*}
Thus, we have the following result for integral processes.

<blockquote class = "prop">

**Properties 10.7. (Lund)** _Let $M(t)$ be a square integrable FV-martingale with predictable variation process $\langle M\rangle(t)$. Let $H(t)$ be a predictable process such that_

$$
\mathbb E\left[\int_0^t H^2(s)\ dV^{\langle M\rangle}(s)\right]<\infty\ \text{or}\ \mathbb E\left[\left(\int_0^t H(s)\ dV^{\langle M\rangle}(s)\right)^2\right]<\infty
$$

_Then_

$$
\int_0^t H(s)\ dM(s)
$$

_is a square integrable FV-martingale and its predictable variation process is given by_

$$
\left\langle \int_0^t H(s)\ dM(s)\right\rangle(t)=\int_0^t H^2(s)\ d\langle M\rangle (s).
$$

</blockquote>

For the predictable covariation process, we have a result corresponding to Proposition 10.7.

<blockquote class = "prop">

**Properties 10.8. (Lund)** _Let $M_1(t)$ and $M_2(t)$ be two FV-martingales such that $\mathbb E[M_1(t)M_2(t)] < \infty$. Let $H(t)$ and $K(t)$ be two predictable processes such that_

$$
\mathbb E\left[\int_0^t \vert H(s) K(s)\vert\ dV^{\langle M_1,M_2\rangle }(s)\right]<\infty.
$$

_Then the predictable covariation process of the integral processes is given by_

$$
\left\langle \int_0^t H(s)\ dM_1(s),\int_0^t H(s)\ dM_2(s)\right\rangle(t)=\int_0^t H(s)K(s)\ d\langle M_1,M_2\rangle (s).
$$

</blockquote>

#### Different look-a-like Fubini results for integral processes

Let $X(t)$ be an FV-process and $H(t)$ a progressive process such that the integral process is well-defined. Due to that $X(t)$ is stochastic (depends on $\omega$), it is not possible directly to apply Fubini Theorem (see Theorem 26.10). Indeed, the mean value $\mathbb E[\int_0^t H(s)\ dX(s)]$ is a number while $\int_0^t\mathbb E[H(s)]\ dX(s)$ is stochastic. However, if we assume that either the integrand or the integrator is deterministic, then there are results that gives condition for changing the order of integrations.

Before we state the condition for changing the order of integrations, we need a preliminary technical lemma.

<blockquote class = "lem">

**Lemma 10.9. (Lund)** _Let $H(t)$ be a measurable process, that is, $H(t)$ is $\mathcal B([0, \infty)) \otimes\mathcal F$ (see Definition 6.7) and let $\mathcal G \subseteq\mathcal F$ be a sub $\sigma$-algebra of $\mathcal F$. Consider $t\mapsto \mathbb E[H(t)\ \vert\ \mathcal G]$ as a stochastic process. Then $\mathbb E[H(t)\ \vert\ \mathcal G]$ admits a version which is $\mathcal B([0, \infty)) \otimes\mathcal G$.If $H(t)$ furthermore is CADLAG then $\mathbb E[H(t)\ \vert\ \mathcal G]$ is also CADLAG._

</blockquote>

If the integrator is deterministic then we have the well known Fubini’s theorem (Theorem 26.10) and moreover the conditional Fubini theorem stated in theorem below. We can change the (conditional) expectation into the integrand.

<blockquote class = "thm">

**Theorem 10.10. (Lund)** _Let $x$ be a deterministic FV-function (see Definition 2.8) and let $H(t)$ be a progressive process satisfying_

$$
\mathbb E\left[\int_0^t\vert H(s)\vert\ dV^x(s)\right]=\int_0^t \mathbb E\vert H(s)\vert\ dV^x(s) <\infty
$$

_for all $t>0$. Then we have Fubini theorem_

$$
\mathbb E\left[\int_0^t H(s)\ dx(s)\right]=\int_0^t \mathbb E[ H(s)]\ dx(s).
$$

_Let $\mathcal G \subseteq\mathcal F$ be a sub $\sigma$-algebra of $\mathcal F$ then we have conditional Fubini_

$$
\mathbb E\left[\left.\int_0^t H(s)\ dx(s)\ \right\vert\ \mathcal G\right]=\int_0^t \mathbb E[ H(s)\ \vert\ \mathcal G]\ dx(s).
$$

</blockquote>

If the integrand is deterministic then we can change the conditional expectation condition the integrator.

<blockquote class = "thm">

**Theorem 10.11. (Lund)** _Let $X(t)$ be an FV-process and let $f(t)$ be a measurable (Borel) function satisfying_

$$
\mathbb E\left[\int_0^t \vert f(s)\vert \ dV^X(s)\right]=\int_0^t f(s)\ d\mathbb E[V
^X(s)] <\infty
$$

_for all $t>0$. Then we have Fubini theorem_

$$
\mathbb E\left[\int_0^t f(s)\ dX(s)\right]=\int_0^t f(s)\ d\mathbb E[X(s)]
$$

_Let $\mathcal G \subseteq\mathcal F$ be a sub $\sigma$-algebra of $\mathcal F$ then we have conditional Fubini_

$$
\mathbb E\left[\left.\int_0^t f(s)\ dX(s)\ \right\vert\ \mathcal G\right]=\int_0^t f(s)\ d\mathbb E[ X(s)\ \vert\ \mathcal G].
$$

</blockquote>

### Counting processes and point processes

Suppose there is an (particular) event occurring repeatedly and random in time. A counting process is a stochastic process that counts the number of the given event that have occurred as time proceeds. For such a process, we will in this note use two equivalent descriptions of the sample paths.

  * Increasing integer-valued piecewise constant functions: (multivariate) counting process.
  * Sequence of points: (multivariate) point process.

A third way to view this process is as a random counting measure, but will not be used in this note.

#### Counting process and point process

### Piecewise constant processes on finite state spaces

## Life insurance models

### General definition of reserves

### Multi-state policy, general model

### Standard multi-state policy, Markov model

### Models with state duration, semi-Markov model

### Surplus and dividends

## Introduction to survival and event history analysis

### Hazard rate (force of mortality)

### Examples of basic counting processes models

### Multiplicative intensity model

### Nonparametric models

### Parametric models
