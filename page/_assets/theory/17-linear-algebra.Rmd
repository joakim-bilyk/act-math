# Linear Algebra
Below is given the abbreviations used when referencing to books:

  - **Wiki**: Wikipedia

## Invertible matrices

This sections study some fundamental properties of the *invertible matrix*\index{invertible matrix}. We start by defining what an invertible matrix is.

<blockquote class = "def">

**Definition.** _Let $A$ be an $n\times m$ matrix and $B$ be an $m\times n$ matrix. We say that $A$ is invertible if_

$$
AB=I_{\min(m,n)}.
$$

_In general, we only consider square matrices. If the above holds we say that $B$ is $A$'s inverse and we write $B=A^{-1}$._

</blockquote>

We can consider some equivalence statements regarding invertible matrices.

<blockquote class = "thm">

**Theorem.** **(The Invertible Matrix Theorem)** _Let $A$ be a $n\times n$ matrix over a field $K$ ($\mathbb{R}^n$), then the following statements are equivalent_

  1. _There exists an $n\times n$ matrix $B$ such that $AB=I_n=BA$._
  2. _There exist either a left inverse $B$ or a right invers $C$ i.e. $BA=I_n=AC$. In this case, $B=C$._
  3. _$A$ has an inverse and is nonsingular and is nondegenerate._
  4. _$A$ is row-equivalent to $I_n$._
  5. _$A$ is column-equivalent to $I_n$._
  6. _$A$ has $n$ pivot positions._
  7. _$A$ has full rank i.e. $\text{rank}(A)=n$ (spans $K$)._
  8. _The equation $Ax=0$ ($x\in K$) has only the trivial solution $x=0$._
  9. _The equation $Ax=b$ has only one solution $x$._
  10. _The kernal of $A$ is trivial i.e. $\text{ker}(A)=\{0\}$._
  11. _The columns of $A$ are linearly independent._
  12. _The columns of $A$ span $K$._
  13. _$\text{span}(A)=K$._
  14. _The columns of $A$ form a basis of $K$._
  15. _The linear transformation $Ax$ is a bijection from $K$ to $K$._
  16. _$A$ has non-zero determinant i.e. $\text{det}(A)\ne 0$._
  17. _$A$ has not 0 as an eigenvalue._
  18. _The transpose of $A$ is invertible._
  19. _$A$ can be expressed as a finite product of elemtary matrices._

</blockquote>

We futhermore have some properties.

<blockquote class = "prop">

**Proposition.** **(Properties)** _Let $A$ be an $n\times n$ invertible matrix. Then_

  1. $(A^{-1})^{-1}=A$
  2. $(kA)^{-1}=k^{-1}A^{-1}$ _with $k\ne 0$._
  3. $(Ax)^+=x^+A^{-1}$ _if $A$ has orthonormal columns. $(\cdot)^+$ denotes the Moore-Penrose inverse and $x$ is a vector._
  4. _If $B$ is an $n\times n$ invertible matrix then $(AB)^{-1}=B^{-1}A^{-1}$._
  5. $\text{det}(A^{-1})=(\text{det}(A))^{-1}$

</blockquote>

The property 2 is especially useful in some settings. Consider for instance

$$
A=
\begin{bmatrix}
\sigma & 0\\
\sigma & \sigma
\end{bmatrix}=\sigma\begin{bmatrix}
1 & 0\\
1 & 1
\end{bmatrix}=\sigma \tilde{A}.
$$

Then we simply find the inverse of $\tilde{A}$ and multiply by $\sigma^{-1}$. That is,

$$
A^{-1}=\frac{1}{\sigma}\tilde{A}^{-1}=\frac{1}{\sigma}
\begin{bmatrix}
1 & 0\\
-1 & 1
\end{bmatrix}=
\begin{bmatrix}
1/\sigma & 0\\
-1/\sigma & 1/\sigma
\end{bmatrix}.
$$

We have an easy propositions regarding diagonal matrices.

<blockquote class = "prop">

**Proposition.** _If $A$ is an diagonal matrix\index{diagonal matrix}, then $A$ is invertible. In particular,_

$$
A^{-1}=\text{diag}(A_{11}^{-1},...,A_{nn}^{-1}).
$$

</blockquote>