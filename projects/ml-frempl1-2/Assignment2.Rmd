---
title: "Comparing and Intereting Machine Learning Algorithms Estimating Technical Prices"
author:
  - name: "Joakim Bilyk, Sebastian Cramer and Teis Blem"
    affiliation: "University of Copenhagen"
date: "`r Sys.Date()`"
abstract: "This document provides a practical example of applications of machine learning algorithms to car insurance data using the `mlr3` package. A popular model used in pricing of non-life insurance policies is the frequency-severity model, where the price is decomposed into the product of the probability of a claim arrises and the expected claim size given a claim occurs. This model is fitted using machine learning algorithms such as penalized linear regression and random forests. This paper argues that the ranger model gives a particular well fit to both the frequency and severity model."
keywords: "mlr3, machine learning, regression, non-life insurance, estimating technical price, XGBoost, Ranger, Bart, Elastic net regression, Generalized Additive Models"
header-includes:
  - \usepackage{subfig}
  - \usepackage{wrapfig}
output:
  pdf_document:
    toc: yes
    toc_depth: '2'
    keep_tex: yes
    template: template.tex
  html_document:
    code_download: yes
    theme: cosmo
    toc_float: yes
    toc: yes
    toc_depth: 2
    highlight: pygments
---
```{r setup}
library(CASdatasets)
library(lattice)
library(evmix)
library(ggplot2)
library(mlr3)
library(mlr3learners)
#library(mlr3extralearners)
library(dbarts)
library(mlr3mbo)
library(mlr3measures)
library(mlr3tuning)
library(ranger)
library(mlr3viz)
library(fastDummies)
library(dplyr)
library(patchwork)
library(xgboost)
library(glex) #remotes::install_github("PlantedML/glex")
library(treeshap) #devtools::install_github('ModelOriented/treeshap')
```

```{r}
## Feature selection and formatting
data("freMPL1",package = "CASdatasets")
#1: RecordBeg and RecordEnd discarded
freMPL1 <- freMPL1 %>%
dplyr::select(-RecordBeg,-RecordEnd)
#1.1: Adding ID to rows
freMPL1 <- cbind(freMPL1,ID = seq(nrow(freMPL1)))
#2: Claim amount and indicator
freMPL1$ClaimAmount[freMPL1$ClaimAmount<0] <- 0
freMPL1$ClaimInd <- ifelse(freMPL1$ClaimAmount>0,1,0)
#3: Electric or GPL vehicals
freMPL1 <- freMPL1 %>%
filter(!(VehEngine %in% c("electric","GPL")))
#4: Combining price categories
levels(freMPL1$VehPrice)[1:3] <- "A-C"
n <- length(levels(freMPL1$VehPrice))
levels(freMPL1$VehPrice)[(n-5):n] <- "U-Z"
n <- length(levels(freMPL1$VehPrice))
levels(freMPL1$VehPrice)[(n-3):(n-1)] <- "R-T"
#5: Combining max speed levels
levels(freMPL1$VehMaxSpeed)[1:2] <- "1-140 kmh"
#6: Bus set to sedan
levels(freMPL1$VehBody)[levels(freMPL1$VehBody) == "bus"] <- "sedan"
#7: SocioCateg change levels
freMPL1 <- freMPL1 %>%
#Get numerical value of SocioCateg
mutate(helper = as.numeric(substr(SocioCateg,4,5))) %>%
#Overwrite SocioCateg
mutate(SocioCateg = factor(ifelse(helper > 50, "C",
ifelse( helper < 50, "A",
"B")),
levels = c("A","B","C"))) %>%
dplyr::select(-helper)
```

First we set up the XGBoost learners with the hyperparameters tuned from the previous assignment.

```{r}
df <- freMPL1
levels(df$VehAge) <- c("0",  "1"  , "8" ,"2"  , "3" ,  "4"  ,"5"   ,"6", "7")
levels(df$Gender) <- c(0,1)
levels(df$MariStat) <- c(0,1)
levels(df$SocioCateg) <- c(0,1,2)
levels(df$VehUsage) <- c(0,1,2,3)
levels(df$VehBody) <- c(0,1,2,3,4,5,6,7)
levels(df$VehPrice) <- c(0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16)
levels(df$VehEnergy) <- c(0,1,2,3)
levels(df$VehEngine) <- c(0,1,2,3,4,5)
levels(df$VehMaxSpeed) <- c(0,1,2,3,4,5,6,7,8)
levels(df$VehClass) <- c(0,1,2,3,4,5)
levels(df$Garage) <- c(0,1,2)
df$VehAge<-as.numeric(df$VehAge)
df$Gender<-as.numeric(df$Gender)
df$MariStat<-as.numeric(df$MariStat)
df$SocioCateg<-as.numeric(df$SocioCateg)
df$VehUsage<- as.numeric(df$VehUsage)
df$VehBody<-as.numeric(df$VehBody)
df$VehPrice<-as.numeric(df$VehPrice)
df$VehMaxSpeed<-as.numeric(df$VehMaxSpeed)
df$VehClass<-as.numeric(df$VehClass)
df$VehEngine<-as.numeric(df$VehEngine)
df$Garage<-as.numeric(df$Garage)
df$VehEnergy <- as.numeric(df$VehEnergy)


df_sev <- df %>% 
  filter(ClaimInd == 1) %>%
  dplyr::select(-Exposure)
row.names(df_sev) <- df_sev$ID
df_sev <- df_sev %>%
  dplyr::select(-ID)

df_freq <- df %>%
  #Make sure not to include ClaimAmount
  dplyr::select(-ClaimAmount)
row.names(df_freq) <- df_freq$ID
df_freq <- df_freq %>%
  dplyr::select(-ID)

df_ff <- df_sev %>% 
  dplyr::select(ClaimAmount,DrivAge,Gender)

xgb_regr <- xgboost(data=as.matrix(df_ff %>% dplyr::select(-ClaimAmount)), label=as.numeric(df_ff[,"ClaimAmount"]), eta = 0.246407, nrounds = 4000, max_depth = 2)

```


```{r}
xgb_regr <- xgboost(data=as.matrix(df_sev %>% dplyr::select(-ClaimAmount)), label=as.numeric(df_sev[,"ClaimAmount"]), eta = 0.246407, nrounds = 4000, max_depth = 2)
xgb_freq <- xgboost(data=as.matrix(df_freq %>% dplyr::select(-ClaimInd)), label=as.numeric(df_freq[,"ClaimInd"]), eta = 0.196547, nrounds = 4000, max_depth = 2, objective="count:poisson")
```

VehAge: 6-7=6 , 8-9 = 7,  10+= 8
Gender: female = 0, male =1
Maristat: alone=0, other = 1
Socialcateg: A,B,C = 0,1,2
VehUsage: Private=0, private+triptooffice=1, professional = 2, professional run =3 
VehBody: seda=0, cabriolet=1,coupe=2,microvan=3, othermicrovan=4, sport=5, station wagon=6, van=7
Price: c(1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16) = "A-C" "D"   "E"   "F"   "G"   "H"   "I"   "J"   "K"   "L"   "M"   "N"   "O"   "P"   "Q"   "R-T" "U-Z"
Engine: c(0,1,2,3,4,5) =  "carburation" "direct injection overpowered" "electric"   "GPL"    "injection"  "injection overpowered" 
Maxspeed: "1-140 kmh" "140-150 km/h" "150-160 km/h" "160-170 km/h" "170-180 km/h" "180-190 km/h" "190-200 km/h" "200-220 km/h" "220+ km/h" = c(0,1,2,3,4,5,6,7,8)
Class: "0"  "A"  "B"  "H"  "M1" "M2"=c(0,1,2,3,4,5)
Garage: "Collective garage" "None"              "Private garage"  =  c(0,1,2)
Energy: c(0,1,2,3) = "diesel"  "eletric" "GPL"     "regular"


```{r}
unified_xgb <- xgboost.unify(xgb_regr,data=as.matrix(df_sev%>% dplyr::select(-ClaimAmount)))

treeshap_xgb <- treeshap(unified_xgb,  df_sev %>% dplyr::select(-ClaimAmount), verbose = 0)

#plot_contribution(treeshap_xgb, obs = 6257)   -  code does not work
plot_feature_importance(treeshap_xgb, max_vars = 10) 
plot_feature_dependence(treeshap_xgb, "LicAge")
plot_feature_dependence(treeshap_xgb, "BonusMalus")
plot_feature_dependence(treeshap_xgb, "DrivAge")
freMPL1[freMPL1$ID==6257,]
```



```{r}
unified_xgb <- xgboost.unify(xgb_freq,data=as.matrix(df_freq %>% dplyr::select(-ClaimInd)))

treeshap_xgb <- treeshap(unified_xgb,  df_freq %>% dplyr::select(-ClaimInd), verbose = 0)

plot_contribution(treeshap_xgb, obs =  6254)
plot_feature_importance(treeshap_xgb, max_vars = 10) 
plot_feature_dependence(treeshap_xgb, "Exposure")
plot_feature_dependence(treeshap_xgb, "LicAge")
plot_feature_dependence(treeshap_xgb, "BonusMalus")
plot_feature_dependence(treeshap_xgb, "DrivAge")

predict(xgb_freq, newdata = as.matrix(df[df$ID==6257,] %>% select(-ClaimInd, -ID, -ClaimAmount)))

```

```{r}
res <- glex(xgb_regr, as.matrix(df_sev$ClaimAmount))
theme_set(theme_minimal(base_size = 13))
vi_xgb <- glex_vi(res)

p_vi <- autoplot(vi_xgb, threshold = 0) + 
  labs(title = NULL, tag = "XGBoost-explanation")

p_vi+
  plot_annotation(title = "Variable importance scores by term") & 
  theme(plot.tag.position = "bottomleft")
```


